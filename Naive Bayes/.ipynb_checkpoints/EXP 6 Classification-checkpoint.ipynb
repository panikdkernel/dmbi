{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aim :** To implement Naive Bayes classifier in python "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theory :** Naive bayes is a relatively simple probabilistic classfication algorithm that is well suitable for categorical data (probabilities can be compuated as simple ratios) and uses the bayes theorem together with a strong (hence \"naive\") independence assumption. The basic idea behind Naive Bayes is that it assigns a probability to every category (finite outcome variable) based on the features in the data and chooses the outcome that is most likely as its prediction.\n",
    "\n",
    "The \"Naive\" in the name refers to the algorithm assuming features in the data are independent conditional on the outcome category. For example suppose we were doing spam text classification, then given a spam text \"Free, sign up now!\", Naive Bayes would assume \"Free\", \"sign\", \"up, \"now\" all occur indepedently of each other (that is $Pr(Free, sign, up, now|spam)$ = $Pr(Free|spam)\\times Pr(sign|spam)\\times Pr(up|spam) \\times Pr(now|spam)$). This conditional independence assumption is considered to be a strong assumption that often doesn't hold in practice, hence the resulting probabilities from Naive Bayes are not to be taken too seriously. However the classifications resulting from Naive Bayes can still be accurate.\n",
    "\n",
    "In machine learning, common application of Naive Bayes are spam email classification, sentiment analysis, document categorization. Naive bayes is advantageous over other commonly used classification algorithms in its simplicity, speed, and its accuracy on small data sets. Since Naive Bayes needs to be trained on a labeled data set it considered to a supervisd learning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA DESCRIPTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using UCI machine learning repository that contains several youtube comments from popular music videos. Each comment is labelled as spam/ham(1/0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>+447935454150 lovely girl talk to me xxx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I always end up coming back to this song&lt;br /&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my sister just received over 6,500 new &lt;a rel=...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cool</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hello I am from Palastine</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  label\n",
       "0           +447935454150 lovely girl talk to me xxx      1\n",
       "1     I always end up coming back to this song<br />      0\n",
       "2  my sister just received over 6,500 new <a rel=...      1\n",
       "3                                               Cool      0\n",
       "4                          Hello I am from Palastine      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading dataset\n",
    "df = pd.read_csv('./YoutubeCommentsSpam.csv')\n",
    "\n",
    "#creating column's labels\n",
    "df.columns = ['comment','label']\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA CLEANING\n",
    "\n",
    "The table shows that this data set consist of 1959 yt comments and 49% of them are ham and 51% are spam. With average length of each comment as 96 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1959.000000</td>\n",
       "      <td>1959.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.512506</td>\n",
       "      <td>94.340480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499971</td>\n",
       "      <td>128.717314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>47.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>97.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1199.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             label       length\n",
       "count  1959.000000  1959.000000\n",
       "mean      0.512506    94.340480\n",
       "std       0.499971   128.717314\n",
       "min       0.000000     2.000000\n",
       "25%       0.000000    28.500000\n",
       "50%       1.000000    47.000000\n",
       "75%       1.000000    97.500000\n",
       "max       1.000000  1199.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add column length\n",
    "df['length'] = df['comment'].map(lambda text:len(text))\n",
    "\n",
    "#summary of dataset\n",
    "df[['label','length']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset into training and testing parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1485.000000\n",
       "mean        0.509764\n",
       "std         0.500073\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         1.000000\n",
       "75%         1.000000\n",
       "max         1.000000\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(75% training and 25% testing)\n",
    "\n",
    "np.random.seed(2017)\n",
    "df['uniform'] = np.random.uniform(0,1,len(df.index))\n",
    "\n",
    "df_train = df[df['uniform'] < 0.75]\n",
    "df_test = df[df['uniform'] > 0.75]\n",
    "\n",
    "df_train['label'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    474.000000\n",
       "mean       0.521097\n",
       "std        0.500083\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        1.000000\n",
       "75%        1.000000\n",
       "max        1.000000\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['label'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPLEMENTING NAIVE BAYES CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique words in df_train: 5898\n",
      "top 5 words: \n",
      " ['Hi.', 'enI', 'album', 'tsÅ«,', 'mv']\n"
     ]
    }
   ],
   "source": [
    "#joining all the comments into a big list\n",
    "train_word_list = ''.join(df_train.iloc[:,0].values)\n",
    "\n",
    "#split the list into unique words\n",
    "train_unique_words = set(train_word_list.split(' '))\n",
    "\n",
    "#number of unique words in df_train\n",
    "vocab_size_train = len(train_unique_words)\n",
    "\n",
    "#summary\n",
    "print('unique words in df_train: %s' % vocab_size_train)\n",
    "print('top 5 words: \\n %s' % list(train_unique_words)[1:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique words in df_train: 5898\n",
      "top 5 words: \n",
      " ['songshicheck', 'itttttttt', 'chanel', 'fit', 'meaty']\n"
     ]
    }
   ],
   "source": [
    "#only keep letters and numbers\n",
    "train_unique_words = [re.sub(r'[^a-zA-Z0-9]','',words) for words in train_unique_words]\n",
    "\n",
    "#convert to lower case and get unique set of words\n",
    "train_unique_words = set([words.lower() for words in train_unique_words])\n",
    "\n",
    "#summary\n",
    "print('unique words in df_train: %s' % vocab_size_train)\n",
    "print('top 5 words: \\n %s' % list(train_unique_words)[1:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict with comment words as 'keys', and their label as 'count'\n",
    "trainSpamWords = dict()\n",
    "trainHamWords = dict()\n",
    "\n",
    "spamWordsCount = 0\n",
    "hamWordsCount = 0\n",
    "\n",
    "#initialize prob. of\n",
    "pSpam = 0.0\n",
    "pHam = 0.0\n",
    "\n",
    "#laplace smoothing\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize dict of words and their labels\n",
    "for word in train_unique_words:\n",
    "    trainSpamWords[word] = 0\n",
    "    trainHamWords[word] = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count no. of times word in comment appear in spam and ham comments\n",
    "def processComment(comment,label):\n",
    "    global spamWordsCount\n",
    "    global hamWordsCount\n",
    "    \n",
    "    #split comment into words\n",
    "    comment = comment.split(' ')\n",
    "    \n",
    "    for word in comment:\n",
    "        #spam comments\n",
    "        if(label == 1 and word != ' '):\n",
    "            trainSpamWords[word] = trainSpamWords.get(word,0)+1\n",
    "            spamWordsCount += 1\n",
    "            \n",
    "        elif(label == 0 and word != ' '):\n",
    "            trainHamWords[word] = trainHamWords.get(word,0)+1\n",
    "            hamWordsCount += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define P(word|spam) and P(word|ham)\n",
    "def conditionalWord(word,label):\n",
    "    \n",
    "    #laplace smoothing\n",
    "    global alpha\n",
    "    \n",
    "    #word in spam comment\n",
    "    if(label == 1):\n",
    "        #P(word|spam)\n",
    "        return (trainSpamWords.get(word,0)+alpha)/(float)(spamWordsCount + vocab_size_train)\n",
    "    \n",
    "    #word in ham comment\n",
    "    if(label == 0):\n",
    "        #P(word|ham)\n",
    "        return (trainHamWords.get(word,0)+alpha)/(float)(hamWordsCount + vocab_size_train)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define P(spam|comment) or P(ham|comment)\n",
    "def conditionalComment(comment,label):\n",
    "    \n",
    "    #initialize conditional prob\n",
    "    prob_label_comment = 1.0\n",
    "    \n",
    "    #Split comments into words\n",
    "    comment = comment.split(' ')\n",
    "    \n",
    "    for word in comment:\n",
    "        prob_label_comment *= conditionalWord(word,label)\n",
    "        \n",
    "    return prob_label_comment    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training here is computing several conditional probs\n",
    "def train():\n",
    "    \n",
    "    global pSpam\n",
    "    global pHam\n",
    "    \n",
    "    #initialize\n",
    "    total = 0\n",
    "    spamCount = 0\n",
    "    \n",
    "    for idx,row in df_train.iterrows():\n",
    "        \n",
    "        if row.label == 1:\n",
    "            spamCount +=1\n",
    "            \n",
    "        total += 1\n",
    "        \n",
    "        processComment(row.comment,row.label)\n",
    "        \n",
    "    #compute prior probabilities P(spam), P(ham)\n",
    "    pSpam = spamCount/float(total)\n",
    "    pHam = (total - spamCount)/float(total)\n",
    "    \n",
    "    print('Training complete')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "# run the train function\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify comment as spam or ham\n",
    "def classify(comment):\n",
    "    \n",
    "    global pSpam\n",
    "    global pHam\n",
    "    \n",
    "    #compute value proportional to P(comment|spam)\n",
    "    isSpam = pSpam * conditionalComment(comment,1)\n",
    "    \n",
    "    #compute value proportional to P(comment|ham)\n",
    "    isHam = pSpam * conditionalComment(comment,0)\n",
    "    \n",
    "    #Output True = spam, False = ham\n",
    "    return (isSpam > isHam)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8037974683544303\n"
     ]
    }
   ],
   "source": [
    "# Initialize spam prediction in test data\n",
    "prediction_test = []\n",
    "\n",
    "# Get prediction accuracy on test data\n",
    "for comment in df_test['comment']:\n",
    "    # CLassify comment\n",
    "    prediction_test.append(classify(comment))\n",
    "    \n",
    "# Check accuracy\n",
    "test_accuracy = np.mean(np.equal(prediction_test, df_test['label']))\n",
    "\n",
    "print('Accuracy: %s' % test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING MODAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spam\n",
    "classify(\"please check out my channel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spam\n",
    "classify('call me on +912321')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ham \n",
    "classify('very nice song keep it up')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ham\n",
    "classify('video was very good I really enjoyed her singing')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USING SK LEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 1 1 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['comment'], df['label'], random_state = 0)\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "X_test_counts = count_vect.transform(X_test)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "pred = clf.predict(X_test_tfidf)\n",
    "print(pred[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[212,  25],\n",
       "       [ 11, 242]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conlusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we have successfully implemented naive bayes classifier to classify youtube comments as spam or not spam."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
